{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP TP2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La apliación está orientado a ser implementado en una empresa de Hotel para automatizar las respuestas y disminuir el tiempo de contestacion y reducir gasto de personal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import random \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchsummary\n",
    "import os\n",
    "import platform\n",
    "import re\n",
    "import unicodedata\n",
    "import stanza\n",
    "import spacy_stanza\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_clean_text(text):    \n",
    "    # sacar tildes de las palabras\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    # quitar caracteres especiales\n",
    "    pattern = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    text = re.sub(pattern, '', text)\n",
    "    # quitar caracteres de puntiación\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amigo tienes habitaciones'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"amigo tienes HABitaciones?..\"\n",
    "\n",
    "# Antes de preprocesar los datos se pasa a mínusculas todo el texto\n",
    "preprocess_clean_text(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 10:52:33 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 12.7MB/s]                    \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/tokenize/ancora.pt: 100%|██████████| 635k/635k [00:00<00:00, 1.71MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/mwt/ancora.pt: 100%|██████████| 601k/601k [00:00<00:00, 1.71MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/pos/ancora.pt: 100%|██████████| 36.8M/36.8M [00:03<00:00, 10.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/lemma/ancora.pt: 100%|██████████| 4.61M/4.61M [00:00<00:00, 6.95MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/constituency/combined.pt: 100%|██████████| 113M/113M [00:11<00:00, 10.1MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/depparse/ancora.pt: 100%|██████████| 136M/136M [00:13<00:00, 9.79MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/sentiment/tass2020.pt: 100%|██████████| 74.0M/74.0M [00:11<00:00, 6.50MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/ner/conll02.pt: 100%|██████████| 67.0M/67.0M [00:09<00:00, 7.19MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/pretrain/fasttextwiki.pt: 100%|██████████| 123M/123M [00:13<00:00, 8.84MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/forward_charlm/newswiki.pt: 100%|██████████| 20.0M/20.0M [00:03<00:00, 6.08MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/pretrain/ancora.pt: 100%|██████████| 107M/107M [00:08<00:00, 12.8MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.5.0/models/backward_charlm/newswiki.pt: 100%|██████████| 20.0M/20.0M [00:02<00:00, 10.0MB/s]\n",
      "2023-06-23 10:54:02 INFO: Loading these models for language: es (Spanish):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | ancora   |\n",
      "| mwt          | ancora   |\n",
      "| pos          | ancora   |\n",
      "| lemma        | ancora   |\n",
      "| constituency | combined |\n",
      "| depparse     | ancora   |\n",
      "| sentiment    | tass2020 |\n",
      "| ner          | conll02  |\n",
      "===========================\n",
      "\n",
      "2023-06-23 10:54:02 INFO: Using device: cuda\n",
      "2023-06-23 10:54:02 INFO: Loading: tokenize\n",
      "2023-06-23 10:54:04 INFO: Loading: mwt\n",
      "2023-06-23 10:54:04 INFO: Loading: pos\n",
      "2023-06-23 10:54:04 INFO: Loading: lemma\n",
      "2023-06-23 10:54:04 INFO: Loading: constituency\n",
      "2023-06-23 10:54:04 INFO: Loading: depparse\n",
      "2023-06-23 10:54:05 INFO: Loading: sentiment\n",
      "2023-06-23 10:54:05 INFO: Loading: ner\n",
      "2023-06-23 10:54:05 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy_stanza.load_pipeline(\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: holas amigo tienes habitaciones\n",
      "Lematización de cada token:\n",
      "[holas, 'hola']\n",
      "[amigo, 'amigo']\n",
      "[tienes, 'tener']\n",
      "[habitaciones, 'habitación']\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de como fuciona\n",
    "text = \"holas amigo tienes HABitaciones?..\"\n",
    "\n",
    "# Antes de preprocesar los datos se pasa a mínusculas todo el texto\n",
    "tokes = nlp(preprocess_clean_text(text.lower()))\n",
    "print(\"tokens:\", tokes)\n",
    "print(\"Lematización de cada token:\")\n",
    "for token in tokes:\n",
    "    print([token, token.lemma_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"intents\": [\n",
    "             {\"tag\": \"bienvenida\",\n",
    "              \"patterns\": [\"Hola\", \"Buenas\", \"¿Qué tal?\",\"Buen dia\"],\n",
    "              \"responses\": [\"Hola! en que puedo ayudarte?\", \"Hola, bienvenido al Hotel Leopard, en que lo ayudo?\"],\n",
    "             },\n",
    "             {\"tag\": \"nombre\",\n",
    "              \"patterns\": [\"¿Cúal es tu nombre?\", \"¿Quién eres?\", \"¿Con quien hablo?\"],\n",
    "              \"responses\": [\"Mi nombre es LeoBot\", \"Yo soy LeoBot\", \"Con LeoBot\"]\n",
    "             },\n",
    "             \n",
    "            {\"tag\": \"contacto\",\n",
    "              \"patterns\": [\"contacto\", \"número de contacto\", \"número de teléfono\", \"número de whatsapp\", \"whatsapp\"],\n",
    "              \"responses\": [\"Podes contactarnos al siguiente 4521321\", \"Contactos al whatsapp 95842234\"]\n",
    "             },\n",
    "            {\"tag\": \"cochera\",\n",
    "              \"patterns\": [\"¿Tiene cochera?\", \"¿Tengo movilidad, quiero cochera?\",\"¿tiene espacio en cochera?\"],\n",
    "              \"responses\": [\"El Hotel cuenta con cochera suficiente para todos los huespedes, no se preocupe.\"]\n",
    "             },\n",
    "            {\"tag\": \"precios\",\n",
    "              \"patterns\": [\"precio de habitacion?\", \"Me podrás pasar los precios\", \"¿Cuánto esta?\", \"¿Cuánto sale?\",\"¿los precios?\"],\n",
    "              \"responses\": [\"Los precios de las habitaciones son las siguientes, habitacion individual a $60, habitacion doble a $100 y habitacion Queen a $160\"]\n",
    "             },\n",
    "            {\"tag\": \"pagos\",\n",
    "              \"patterns\": [\"medios de pago\", \"tarjeta de crédito\", \"tarjeta debito\", \"plin o yape\",\"¿para cancelar?\",\"el pago\",\"para cancelar\"],\n",
    "              \"responses\": [\"Puede realizar la reserva por la pagina web www.leopard-hotel.com ó por medio fisico con tarjeta o transferencia\"]\n",
    "             },\n",
    "            {\"tag\": \"disponibilidad\",\n",
    "              \"patterns\": [\"¿Hay habitaciones?\", \"¿Tiene habitaciones?\", \"¿Hoy hay habitaciones?\"],\n",
    "              \"responses\": [\"Puede resalizar la reserva por la pagina web www.leopard-hotel.com\"]\n",
    "             },\n",
    "            {\"tag\": \"agradecimientos\",\n",
    "              \"patterns\": [ \"Muchas gracias\", \"Gracias\",\"eso es todo\"],\n",
    "              \"responses\": [\"Que tenga buen dia, cualquier otra consulta puedes escribirme\"]\n",
    "             },\n",
    "             {\"tag\": \"despedida\",\n",
    "              \"patterns\": [ \"Ok nos vemos\", \"Hasta luego!\", \"chau\", \"bye\"],\n",
    "              \"responses\": [\"Hasta luego!\", \"Hablamos luego!\"]\n",
    "             }\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos que necesitaremos, las palabras o vocabilario\n",
    "words = []\n",
    "classes = []\n",
    "doc_X = []\n",
    "doc_y = []\n",
    "\n",
    "# Por cada intención (intents) debemos tomar los patrones que la caracterízan\n",
    "# a esa intención y transformarla a tokens para lamacenar en doc_X\n",
    "\n",
    "# El tag de cada intención se almacena como doc_Y (la clase a predecir)\n",
    "\n",
    "for intent in dataset[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        # trasformar el patron a tokens\n",
    "        tokens = nlp(preprocess_clean_text(pattern.lower()))\n",
    "        # lematizar los tokens\n",
    "        for token in tokens:            \n",
    "            words.append(token.lemma_)\n",
    "        \n",
    "        doc_X.append(pattern)\n",
    "        doc_y.append(intent[\"tag\"])\n",
    "    \n",
    "    # Agregar el tag a las clases\n",
    "    if intent[\"tag\"] not in classes:\n",
    "        classes.append(intent[\"tag\"])\n",
    "\n",
    "# Elminar duplicados con \"set\" y ordenar el vocubulario y las clases por orden alfabético\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['buen', 'bye', 'cancelar', 'chau', 'cochera', 'con', 'contacto', 'credito', 'cual', 'cuanto', 'de', 'debito', 'dia', 'el', 'en', 'ese', 'espacio', 'este', 'gracias', 'haber', 'habitacion', 'habitación', 'hablar', 'hasta', 'hola', 'hoy', 'luego', 'medio', 'movilidad', 'mucho', 'nombre', 'numero', 'o', 'ok', 'pago', 'para', 'pasar', 'plin', 'poder', 'precio', 'que', 'querer', 'quien', 'salir', 'ser', 'tal', 'tarjeta', 'telefono', 'tener', 'todo', 'tu', 'ver', 'whatsapp', 'yape', 'yo']\n",
      "classes: ['agradecimientos', 'bienvenida', 'cochera', 'contacto', 'despedida', 'disponibilidad', 'nombre', 'pagos', 'precios']\n",
      "doc_X: ['Hola', 'Buenas', '¿Qué tal?', 'Buen dia', '¿Cúal es tu nombre?', '¿Quién eres?', '¿Con quien hablo?', 'contacto', 'número de contacto', 'número de teléfono', 'número de whatsapp', 'whatsapp', '¿Tiene cochera?', '¿Tengo movilidad, quiero cochera?', '¿tiene espacio en cochera?', 'precio de habitacion?', 'Me podrás pasar los precios', '¿Cuánto esta?', '¿Cuánto sale?', '¿los precios?', 'medios de pago', 'tarjeta de crédito', 'tarjeta debito', 'plin o yape', '¿para cancelar?', 'el pago', 'para cancelar', '¿Hay habitaciones?', '¿Tiene habitaciones?', '¿Hoy hay habitaciones?', 'Muchas gracias', 'Gracias', 'eso es todo', 'Ok nos vemos', 'Hasta luego!', 'chau', 'bye']\n",
      "doc_y: ['bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'nombre', 'nombre', 'nombre', 'contacto', 'contacto', 'contacto', 'contacto', 'contacto', 'cochera', 'cochera', 'cochera', 'precios', 'precios', 'precios', 'precios', 'precios', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'pagos', 'disponibilidad', 'disponibilidad', 'disponibilidad', 'agradecimientos', 'agradecimientos', 'agradecimientos', 'despedida', 'despedida', 'despedida', 'despedida']\n"
     ]
    }
   ],
   "source": [
    "print(\"words:\", words)\n",
    "print(\"classes:\", classes)\n",
    "print(\"doc_X:\", doc_X)\n",
    "print(\"doc_y:\", doc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 55\n",
      "Tags: 9\n"
     ]
    }
   ],
   "source": [
    "# Tamaño del vocabulario\n",
    "print(\"Vocabulario:\", len(words))\n",
    "# Cantidad de tags\n",
    "print(\"Tags:\", len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] y: [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "X: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "X: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1] y: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "X: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "X: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Transformar doc_X en bag of words por oneHotEncoding\n",
    "# Transformar doc_Y en un vector de clases multicategórico con oneHotEncoding\n",
    "\n",
    "training = []\n",
    "out_empty = [0] * len(classes)\n",
    "\n",
    "for idx, doc in enumerate(doc_X):\n",
    "    # Transformar la pregunta (input) en tokens y lematizar\n",
    "    text = []\n",
    "    tokens = nlp(preprocess_clean_text(doc.lower()))\n",
    "    for token in tokens:\n",
    "        text.append(token.lemma_)\n",
    "\n",
    "    # Transformar los tokens en \"Bag of words\" (arrays de 1 y 0)\n",
    "    bow = []\n",
    "    for word in words:\n",
    "        bow.append(1) if word in text else bow.append(0)\n",
    "    \n",
    "    # Crear el array de salida (class output) correspondiente\n",
    "    output_row = list(out_empty)\n",
    "    output_row[classes.index(doc_y[idx])] = 1\n",
    "\n",
    "    print(\"X:\", bow, \"y:\", output_row)\n",
    "    training.append([bow, output_row])\n",
    "\n",
    "# Mezclar los datos\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "# Dividir en datos de entrada y salida\n",
    "train_X = np.array(list(training[:, 0]))\n",
    "train_y = np.array(list(training[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dim 55\n",
      "Output dim 9\n"
     ]
    }
   ],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        # Convertir los arrays de numpy a tensores. \n",
    "        # pytorch espera en general entradas 32bits\n",
    "        self.x = torch.from_numpy(x.astype(np.float32))\n",
    "        # las loss function esperan la salida float\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "        self.len = self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "data_set = Data(train_X, train_y)\n",
    "\n",
    "input_dim = data_set.x.shape[1]\n",
    "print(\"Input dim\", input_dim)\n",
    "\n",
    "output_dim = data_set.y.shape[1]\n",
    "print(\"Output dim\", output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(data_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 128]           7,168\n",
      "              ReLU-2               [-1, 1, 128]               0\n",
      "           Dropout-3               [-1, 1, 128]               0\n",
      "            Linear-4                [-1, 1, 64]           8,256\n",
      "              ReLU-5                [-1, 1, 64]               0\n",
      "           Dropout-6                [-1, 1, 64]               0\n",
      "            Linear-7                 [-1, 1, 9]             585\n",
      "           Softmax-8                 [-1, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 16,009\n",
      "Trainable params: 16,009\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_dim, out_features=128) # fully connected layer\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=64) # fully connected layer\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=output_dim) # fully connected layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1) # normalize in dim 1\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.softmax(self.fc3(out))\n",
    "        return out\n",
    "\n",
    "# Crear el modelo basado en la arquitectura definida\n",
    "model1 = Model1(input_dim=input_dim, output_dim=output_dim)\n",
    "# Crear el optimizador la una función de error\n",
    "model1_optimizer = torch.optim.Adam(model1.parameters(), lr=0.005)\n",
    "model1_criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
    "\n",
    "torchsummary.summary(model1, input_size=(1, input_dim), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_helpers import categorical_acc\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, epochs=100):\n",
    "    # Defino listas para realizar graficas de los resultados\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "\n",
    "    ## Defino mi loop de entrenamiento\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_accuracy = 0.0\n",
    "\n",
    "        for train_data, train_target in train_loader:\n",
    "\n",
    "            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n",
    "            # los va acumulando\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(train_data)\n",
    "\n",
    "            # Computo el error de la salida comparando contra las etiquetas\n",
    "            loss = criterion(output, train_target)\n",
    "\n",
    "            # Almaceno el error del batch para luego tener el error promedio de la epoca\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "            # Computo el nuevo set de gradientes a lo largo de toda la red\n",
    "            loss.backward()\n",
    "\n",
    "            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculo el accuracy del batch\n",
    "            accuracy = categorical_acc(output, train_target)\n",
    "            # Almaceno el accuracy del batch para luego tener el accuracy promedio de la epoca\n",
    "            epoch_train_accuracy += accuracy.item()\n",
    "\n",
    "        # Calculo la media de error y accuracy para la epoca de entrenamiento.\n",
    "        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
    "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)        \n",
    "        train_accuracy.append(epoch_train_accuracy)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f}\")\n",
    "\n",
    "    history = {\n",
    "        \"loss\": train_loss,\n",
    "        \"accuracy\": train_accuracy,\n",
    "    }\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/120 - Train loss 2.198 - Train accuracy 0.047\n",
      "Epoch: 2/120 - Train loss 2.195 - Train accuracy 0.062\n",
      "Epoch: 3/120 - Train loss 2.192 - Train accuracy 0.225\n",
      "Epoch: 4/120 - Train loss 2.184 - Train accuracy 0.425\n",
      "Epoch: 5/120 - Train loss 2.174 - Train accuracy 0.456\n",
      "Epoch: 6/120 - Train loss 2.172 - Train accuracy 0.472\n",
      "Epoch: 7/120 - Train loss 2.166 - Train accuracy 0.294\n",
      "Epoch: 8/120 - Train loss 2.144 - Train accuracy 0.425\n",
      "Epoch: 9/120 - Train loss 2.128 - Train accuracy 0.441\n",
      "Epoch: 10/120 - Train loss 2.127 - Train accuracy 0.394\n",
      "Epoch: 11/120 - Train loss 2.107 - Train accuracy 0.425\n",
      "Epoch: 12/120 - Train loss 2.077 - Train accuracy 0.409\n",
      "Epoch: 13/120 - Train loss 1.989 - Train accuracy 0.409\n",
      "Epoch: 14/120 - Train loss 1.985 - Train accuracy 0.409\n",
      "Epoch: 15/120 - Train loss 1.958 - Train accuracy 0.494\n",
      "Epoch: 16/120 - Train loss 1.927 - Train accuracy 0.394\n",
      "Epoch: 17/120 - Train loss 1.882 - Train accuracy 0.525\n",
      "Epoch: 18/120 - Train loss 1.903 - Train accuracy 0.588\n",
      "Epoch: 19/120 - Train loss 1.821 - Train accuracy 0.603\n",
      "Epoch: 20/120 - Train loss 1.824 - Train accuracy 0.603\n",
      "Epoch: 21/120 - Train loss 1.782 - Train accuracy 0.719\n",
      "Epoch: 22/120 - Train loss 1.762 - Train accuracy 0.766\n",
      "Epoch: 23/120 - Train loss 1.727 - Train accuracy 0.650\n",
      "Epoch: 24/120 - Train loss 1.703 - Train accuracy 0.781\n",
      "Epoch: 25/120 - Train loss 1.670 - Train accuracy 0.812\n",
      "Epoch: 26/120 - Train loss 1.692 - Train accuracy 0.812\n",
      "Epoch: 27/120 - Train loss 1.639 - Train accuracy 0.859\n",
      "Epoch: 28/120 - Train loss 1.590 - Train accuracy 0.828\n",
      "Epoch: 29/120 - Train loss 1.553 - Train accuracy 0.859\n",
      "Epoch: 30/120 - Train loss 1.543 - Train accuracy 0.859\n",
      "Epoch: 31/120 - Train loss 1.548 - Train accuracy 0.875\n",
      "Epoch: 32/120 - Train loss 1.544 - Train accuracy 0.891\n",
      "Epoch: 33/120 - Train loss 1.501 - Train accuracy 0.906\n",
      "Epoch: 34/120 - Train loss 1.538 - Train accuracy 0.875\n",
      "Epoch: 35/120 - Train loss 1.512 - Train accuracy 0.891\n",
      "Epoch: 36/120 - Train loss 1.471 - Train accuracy 0.922\n",
      "Epoch: 37/120 - Train loss 1.543 - Train accuracy 0.906\n",
      "Epoch: 38/120 - Train loss 1.485 - Train accuracy 0.922\n",
      "Epoch: 39/120 - Train loss 1.477 - Train accuracy 0.906\n",
      "Epoch: 40/120 - Train loss 1.491 - Train accuracy 0.922\n",
      "Epoch: 41/120 - Train loss 1.514 - Train accuracy 0.922\n",
      "Epoch: 42/120 - Train loss 1.455 - Train accuracy 0.953\n",
      "Epoch: 43/120 - Train loss 1.485 - Train accuracy 0.922\n",
      "Epoch: 44/120 - Train loss 1.449 - Train accuracy 0.953\n",
      "Epoch: 45/120 - Train loss 1.481 - Train accuracy 0.922\n",
      "Epoch: 46/120 - Train loss 1.451 - Train accuracy 0.953\n",
      "Epoch: 47/120 - Train loss 1.456 - Train accuracy 0.938\n",
      "Epoch: 48/120 - Train loss 1.441 - Train accuracy 0.969\n",
      "Epoch: 49/120 - Train loss 1.417 - Train accuracy 0.984\n",
      "Epoch: 50/120 - Train loss 1.416 - Train accuracy 0.984\n",
      "Epoch: 51/120 - Train loss 1.415 - Train accuracy 1.000\n",
      "Epoch: 52/120 - Train loss 1.407 - Train accuracy 0.984\n",
      "Epoch: 53/120 - Train loss 1.412 - Train accuracy 0.984\n",
      "Epoch: 54/120 - Train loss 1.407 - Train accuracy 1.000\n",
      "Epoch: 55/120 - Train loss 1.420 - Train accuracy 0.984\n",
      "Epoch: 56/120 - Train loss 1.460 - Train accuracy 0.969\n",
      "Epoch: 57/120 - Train loss 1.413 - Train accuracy 1.000\n",
      "Epoch: 58/120 - Train loss 1.385 - Train accuracy 1.000\n",
      "Epoch: 59/120 - Train loss 1.389 - Train accuracy 1.000\n",
      "Epoch: 60/120 - Train loss 1.405 - Train accuracy 1.000\n",
      "Epoch: 61/120 - Train loss 1.390 - Train accuracy 1.000\n",
      "Epoch: 62/120 - Train loss 1.398 - Train accuracy 1.000\n",
      "Epoch: 63/120 - Train loss 1.409 - Train accuracy 0.984\n",
      "Epoch: 64/120 - Train loss 1.388 - Train accuracy 1.000\n",
      "Epoch: 65/120 - Train loss 1.394 - Train accuracy 1.000\n",
      "Epoch: 66/120 - Train loss 1.395 - Train accuracy 1.000\n",
      "Epoch: 67/120 - Train loss 1.389 - Train accuracy 1.000\n",
      "Epoch: 68/120 - Train loss 1.390 - Train accuracy 1.000\n",
      "Epoch: 69/120 - Train loss 1.381 - Train accuracy 1.000\n",
      "Epoch: 70/120 - Train loss 1.384 - Train accuracy 1.000\n",
      "Epoch: 71/120 - Train loss 1.376 - Train accuracy 1.000\n",
      "Epoch: 72/120 - Train loss 1.378 - Train accuracy 1.000\n",
      "Epoch: 73/120 - Train loss 1.393 - Train accuracy 1.000\n",
      "Epoch: 74/120 - Train loss 1.396 - Train accuracy 0.984\n",
      "Epoch: 75/120 - Train loss 1.379 - Train accuracy 1.000\n",
      "Epoch: 76/120 - Train loss 1.404 - Train accuracy 1.000\n",
      "Epoch: 77/120 - Train loss 1.388 - Train accuracy 1.000\n",
      "Epoch: 78/120 - Train loss 1.378 - Train accuracy 1.000\n",
      "Epoch: 79/120 - Train loss 1.381 - Train accuracy 1.000\n",
      "Epoch: 80/120 - Train loss 1.374 - Train accuracy 1.000\n",
      "Epoch: 81/120 - Train loss 1.387 - Train accuracy 1.000\n",
      "Epoch: 82/120 - Train loss 1.375 - Train accuracy 1.000\n",
      "Epoch: 83/120 - Train loss 1.402 - Train accuracy 1.000\n",
      "Epoch: 84/120 - Train loss 1.379 - Train accuracy 1.000\n",
      "Epoch: 85/120 - Train loss 1.390 - Train accuracy 1.000\n",
      "Epoch: 86/120 - Train loss 1.382 - Train accuracy 1.000\n",
      "Epoch: 87/120 - Train loss 1.373 - Train accuracy 1.000\n",
      "Epoch: 88/120 - Train loss 1.381 - Train accuracy 1.000\n",
      "Epoch: 89/120 - Train loss 1.374 - Train accuracy 1.000\n",
      "Epoch: 90/120 - Train loss 1.374 - Train accuracy 1.000\n",
      "Epoch: 91/120 - Train loss 1.374 - Train accuracy 1.000\n",
      "Epoch: 92/120 - Train loss 1.379 - Train accuracy 1.000\n",
      "Epoch: 93/120 - Train loss 1.373 - Train accuracy 1.000\n",
      "Epoch: 94/120 - Train loss 1.374 - Train accuracy 1.000\n",
      "Epoch: 95/120 - Train loss 1.373 - Train accuracy 1.000\n",
      "Epoch: 96/120 - Train loss 1.380 - Train accuracy 1.000\n",
      "Epoch: 97/120 - Train loss 1.385 - Train accuracy 1.000\n",
      "Epoch: 98/120 - Train loss 1.381 - Train accuracy 0.984\n",
      "Epoch: 99/120 - Train loss 1.377 - Train accuracy 1.000\n",
      "Epoch: 100/120 - Train loss 1.403 - Train accuracy 0.984\n",
      "Epoch: 101/120 - Train loss 1.374 - Train accuracy 1.000\n",
      "Epoch: 102/120 - Train loss 1.375 - Train accuracy 1.000\n",
      "Epoch: 103/120 - Train loss 1.391 - Train accuracy 0.969\n",
      "Epoch: 104/120 - Train loss 1.398 - Train accuracy 1.000\n",
      "Epoch: 105/120 - Train loss 1.375 - Train accuracy 1.000\n",
      "Epoch: 106/120 - Train loss 1.376 - Train accuracy 1.000\n",
      "Epoch: 107/120 - Train loss 1.389 - Train accuracy 0.984\n",
      "Epoch: 108/120 - Train loss 1.379 - Train accuracy 1.000\n",
      "Epoch: 109/120 - Train loss 1.374 - Train accuracy 1.000\n",
      "Epoch: 110/120 - Train loss 1.389 - Train accuracy 0.984\n",
      "Epoch: 111/120 - Train loss 1.377 - Train accuracy 1.000\n",
      "Epoch: 112/120 - Train loss 1.375 - Train accuracy 1.000\n",
      "Epoch: 113/120 - Train loss 1.375 - Train accuracy 1.000\n",
      "Epoch: 114/120 - Train loss 1.373 - Train accuracy 1.000\n",
      "Epoch: 115/120 - Train loss 1.376 - Train accuracy 1.000\n",
      "Epoch: 116/120 - Train loss 1.373 - Train accuracy 1.000\n",
      "Epoch: 117/120 - Train loss 1.378 - Train accuracy 1.000\n",
      "Epoch: 118/120 - Train loss 1.378 - Train accuracy 1.000\n",
      "Epoch: 119/120 - Train loss 1.378 - Train accuracy 1.000\n",
      "Epoch: 120/120 - Train loss 1.373 - Train accuracy 1.000\n"
     ]
    }
   ],
   "source": [
    "history1 = train(model1,\n",
    "                train_loader,\n",
    "                model1_optimizer,\n",
    "                model1_criterion,\n",
    "                epochs=120\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_count = range(1, len(history1['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history1['accuracy'], label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tokens(text): \n",
    "    lemma_tokens = []\n",
    "    tokens = nlp(preprocess_clean_text(text.lower()))\n",
    "    for token in tokens:\n",
    "        lemma_tokens.append(token.lemma_)\n",
    "    #print(lemma_tokens)\n",
    "    return lemma_tokens\n",
    "\n",
    "def bag_of_words(text, vocab): \n",
    "    tokens = text_to_tokens(text)\n",
    "    bow = [0] * len(vocab)\n",
    "    for w in tokens: \n",
    "        for idx, word in enumerate(vocab):\n",
    "            if word == w: \n",
    "                bow[idx] = 1\n",
    "    #print(bow)\n",
    "    return np.array(bow)\n",
    "\n",
    "def pred_class(text, vocab, labels): \n",
    "    bow = bag_of_words(text, vocab)\n",
    "    words_recognized = sum(bow)\n",
    "\n",
    "    return_list = []\n",
    "    if words_recognized > 0:\n",
    "        x = torch.from_numpy(np.array([bow]).astype(np.float32))\n",
    "        result = model1(x)[0].detach().numpy()\n",
    "        thresh = 0.2\n",
    "        y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
    "        y_pred.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        for r in y_pred:\n",
    "            return_list.append(labels[r[0]])\n",
    "            #print(labels[r[0]], r[1])\n",
    "\n",
    "    return return_list\n",
    "\n",
    "def get_response(intents_list, intents_json):\n",
    "    tag = intents_list[0]\n",
    "    list_of_intents = intents_json[\"intents\"]\n",
    "    for i in list_of_intents: \n",
    "        if i[\"tag\"] == tag:\n",
    "            result = \"BOT: \" + random.choice(i[\"responses\"])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: Hola! en que puedo ayudarte?\n"
     ]
    }
   ],
   "source": [
    "message = \"Buenas\"\n",
    "intents = pred_class(message, words, classes)\n",
    "if len(intents) > 0:\n",
    "    result = get_response(intents, dataset)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREGUNTA:  hola\n",
      "RESPUESTA  BOT: Hola, bienvenido al Hotel Leopard, en que lo ayudo?\n",
      "PREGUNTA:  tienes cochera?\n",
      "RESPUESTA  BOT: El Hotel cuenta con cochera suficiente para todos los huespedes, no se preocupe.\n",
      "PREGUNTA:  el pago puedo hacerlo con tarjeta?\n",
      "RESPUESTA  BOT: Puede realizar la reserva por la pagina web www.leopard-hotel.com ó por medio fisico con tarjeta o transferencia\n",
      "PREGUNTA:  los precios de las habitaciones?\n",
      "RESPUESTA  BOT: Los precios de las habitaciones son las siguientes, habitacion individual a $60, habitacion doble a $100 y habitacion Queen a $160\n",
      "PREGUNTA:  ok gracias\n",
      "RESPUESTA  BOT: Hasta luego!\n",
      "PREGUNTA:  nos vemos\n",
      "RESPUESTA  BOT: Hasta luego!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message = input(\"\")\n",
    "    \n",
    "    if message=='exit':\n",
    "        break\n",
    "    \n",
    "    print('PREGUNTA: ',message)\n",
    "    \n",
    "    intents = pred_class(message, words, classes)\n",
    "    if len(intents) > 0:\n",
    "        result = get_response(intents, dataset)\n",
    "        print('RESPUESTA ',result)\n",
    "    else:\n",
    "        print(\"Perdón, no comprendo la pregunta.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conslusiones:\n",
    "\n",
    "- El modelo implementado para la generación de un bot obtiene respuestas acordes a la solicitud.\n",
    "\n",
    "- El modelo se puede mejorar incrementando los tokens realacionados a cada clase.\n",
    "\n",
    "- La aplicación y los datos utilizados son para una aplicación de brindar información de un Hotel.\n",
    "\n",
    "- Aumentandoi ligeramente la tasa de aprendizaje el modelo logra con mejor precision y en menos epocas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvi_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
